{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c296fb49-47f3-4537-baaa-57148e84551e",
   "metadata": {},
   "source": [
    "# Introdução à NLP\n",
    "\n",
    "> NLP = Natural language processing\n",
    "\n",
    "É o campo de estudo que faz os computadores \"entenderem\" texto. \n",
    "Também conhecida com mineração de texto, essa atividade pode ser usada para saber o que as pessoas estão falando em redes sociais ao usar databases ou fazer web scrapping, também é usado na criação da inteligência artificial de chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6597d4c-2eb3-4b51-804a-76ed9c4941e4",
   "metadata": {},
   "source": [
    "### Alguns conceitos\n",
    "\n",
    "- Wordnet (dicionário lexico): é tipo uma grande database que reune palavras e agrupa ela por categorias (parece mais com um dicionário na real).\n",
    "- Part of speech: é uma tecnologia/metodologia que consegue destrinchar os verbos, substantivos, etc de uma frase.\n",
    "- Reconhecimento de Entidades: relaciona as part of speech (tipo, o programa entende o que ou sobre o que estão falando).\n",
    "- Análise de Sentimentos: É uma analise sobre o \"sentimento\" da frase, tipo, está falando mau ou bem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc536ed-35cb-49ee-bf77-d0b6440b1d17",
   "metadata": {},
   "source": [
    "### Um pouco sobre strings\n",
    "\n",
    "strings são frases ou palavras que podemos armazenar no computador. Strings, na realidade, são um vetor de caracteres, onde cada caractere é interpretado pelo computador como um número (pesquise sobre tabela ASCII).\n",
    "OBS: O espaço em branco ' ' também é um caractere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3f9e1-e8ff-4c8f-8319-723ae1737838",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_1 = \"string é a mesma coisa que uma frase, mas também pode ser só uma\"\n",
    "string_2 = \"palavra\"\n",
    "string_3 = \"\"\"\n",
    "string com\n",
    "varias\n",
    "linhas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44512619-1b71-4037-9b61-1759f9c99d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(string_1, string_2)\n",
    "print(string_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82fffe-8aaf-4a71-986d-d58b6aa81316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"linhas\" in string_3:\n",
    "    print(\"yes\")\n",
    "\n",
    "print(string_2[:3])\n",
    "    \n",
    "for i in range(len(string_1)):\n",
    "    print(string_1[i])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26947431-d76b-4164-9fd1-65cd8a7b4515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vetor_3 = string_3.split(\" \")\n",
    "print(vetor)\n",
    "\n",
    "vetor_1 = string_1.split(\" \")\n",
    "vetor_1.append(string_2)\n",
    "juntando =  \" \".join(vetor_1)\n",
    "print(juntando[0:juntando.index(\"palavra\") - 1] == string_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edfd52-a58a-4403-aac2-fab2f0f246d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fstring = f\"{string_1} + {string_2}\"\n",
    "print(fstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a484c55-462b-4964-aaa3-2ff11f3c41ea",
   "metadata": {},
   "source": [
    "### Biblioteca nltk\n",
    "\n",
    "É a biblioteca que usaremos para fazer text mining. Documentação [aqui](https://www.nltk.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd397e-a47d-482e-ae35-bb5a1e203243",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk\n",
    "import nltk\n",
    "nltk.download()\n",
    "\n",
    "# escreva \"d\" depois \"all\" e por fim \"q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c77a6-cf88-4906-b0c7-233306ed17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"Sujeito adjetivo substantivo verbo adverbio verbo, arroz!\"\n",
    "palavras = nltk.word_tokenize(frase)\n",
    "freq = nltk.FreqDist(frase)\n",
    "print(palavras, type(palavras))\n",
    "print(freq.max(), type(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a53d20-3a2d-4b8a-b462-2d638c4378fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steamming (pega o radical/raiz da palavra)\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "print(stemmer.stem(\"correu\"), stemmer.stem(\"corredor\"), stemmer.stem(\"correria\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f5b08-9ba9-4a58-830a-614f6b8610c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization (pega a \"forma geral\" da palavra)\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "print (lemmatizer.lemmatize(\"running\", pos=\"v\")) # só em inglês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041ccc6-c7a9-4287-bd98-4b3752d92072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords (conjunções, preposições, artigos e outras palavras)\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "print(stopwords[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1510e4-e701-4700-af25-a215dbd862fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonsenseRemove(frase):\n",
    "    frase = frase.lower()\n",
    "    lista = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    util = [palavra for palavra in frase.split() if not palavra in lista]\n",
    "    return (\" \".join(util))\n",
    "    \n",
    "f = \"nossa como o ceu está lindo, eu já deveria ter parado de escrever\"\n",
    "print(f)\n",
    "f = nonsenseRemove(f)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7c306-6500-4be5-814b-ebcf10c61087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of speech - só em inglês\n",
    "text = nltk.word_tokenize(\"I don't speak english\")\n",
    "nltk.pos_tag(text)\n",
    "nltk.help.upenn_tagset('VBP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
