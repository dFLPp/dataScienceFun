{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5d9fd0-3a67-424e-ae98-d87276028bd1",
   "metadata": {},
   "source": [
    "# Procedimento básico de pre-processamento de dados\n",
    "\n",
    "> Idealmente você deve fazer um pre-processamento externo, com o pandas por exemplo, antes de começar a fazer machine learning\n",
    "\n",
    "Passos\n",
    "1. bibliotecas\n",
    "2. datasets e variaveis\n",
    "3. valores faltantes\n",
    "4. encoding\n",
    "5. dados de treino e de teste\n",
    "6. corrigindo a escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9ffaa-6d3d-4bf3-93e1-faeee80a7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba11168-91cf-4281-8de0-d6bf55767850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds e working vars\n",
    "\n",
    "ds = pd.read_csv('./data.csv')\n",
    "values = ds.iloc[:, :3].values\n",
    "classes = ds.iloc[:, 3].values\n",
    "# ao usar '.values' transforma a pd.series em np.narray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a72f26-74b2-4107-82ed-f8ecf2be297d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#substituindo os valores 'na' pela media da coluna (np.narray)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "\n",
    "imputer.fit(values[:, 1:3]) #todas as linhas, menos a primeira coluna\n",
    "values[:, 1:3] = imputer.transform(values[:, 1:3]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e713e-d761-46a4-ac82-abf5724f782b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values[:, 0]\n",
    "#obs: poderia estar trabalhando com padas tranquilamente btw\n",
    "# tipo, ao invés de usar arrays com essa formatação feia usar Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e8c2f-1602-452a-b962-391f8ea917fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#re-significando as \"classes\". tipo, o algoritimo não entende a diferença entre 'frança' e espanha\n",
    "# dessa forma precisamos substituir 'frança' por 1 e 'espanha' por 2, dessa forma 1 != 2 (o pc só entende números)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "values[ : , 0] = oe.fit_transform(values[ : , 0].reshape(-1, 1)).reshape(-1)\n",
    "values[ : , 0] = values[ : , 0].astype(int)\n",
    "# OBS prox. celula\n",
    "\n",
    "labelencoder_Y = LabelEncoder()\n",
    "classes = labelencoder_Y.fit_transform(classes)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0faf81-9b0e-4e8a-82af-5e17a26580e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBS\n",
    "\n",
    "# O encoder preicsa dos dados no formato 2d, ou seja, [ ['France', 'Spain', 'Germany'] ]\n",
    "# mas ele estava recebendo no formado 1d, ou seja ['France', 'Spain', 'Germany'].\n",
    "x = np.array(['France', 'Spain', 'Germany', 'Spain', 'Germany', 'France',\n",
    "       'Spain', 'France', 'Germany', 'France'])\n",
    "print(x, x.shape)\n",
    "#transformando:\n",
    "nx = (x.reshape(-1,1))\n",
    "print(nx, nx.shape)\n",
    "#des transformando\n",
    "nx = nx.reshape(-1)\n",
    "# nx = nx.ravel()\n",
    "print(nx, nx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c266b2-b280-4962-b695-b353ab4b206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados aleatoriamente para treino e teste\n",
    "# tipo, de 100 numeros, pega 80 aleatoriamente depois pega mais 20 aleatoriamente (por isso 0.2)\n",
    "# como nesse contexto vamos usar ML, é comum chamar de traino e de teste\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "v_train, v_test, c_train, c_test = train_test_split(values, classes, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0161289-53bd-40d8-9101-828adf96ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deixando os dados na mesma escala, por exemplo, ao usar z-score\n",
    "# porque = números muito grandes \"pesam\" mais computacionalmente\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "v_train = ss.fit_transform(v_train)\n",
    "v_test = ss.fit_transform(v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b99d18-c77e-4afd-848b-40f25dfb5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_train\n",
    "# ele faz a escala de acordo com a coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656a594-317b-4e33-b38a-9d5fff3d06e4",
   "metadata": {},
   "source": [
    "## bibliografia\n",
    "https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%201_Data%20PreProcessing.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
